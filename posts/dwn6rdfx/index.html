<!doctype html><html lang="zh-CN"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="generator" content="VuePress 2.0.0-rc.19" /><meta name="theme" content="VuePress Theme Plume " /><script id="check-mac-os">document.documentElement.classList.toggle('mac', /Mac|iPhone|iPod|iPad/i.test(navigator.platform))</script><script id="check-dark-mode">;(function () {const um= localStorage.getItem('vuepress-theme-appearance') || 'auto';const sm = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;const isDark = um === 'dark' || (um !== 'light' && sm);document.documentElement.dataset.theme = isDark ? 'dark' : 'light';})();</script><meta property="og:url" content="https://physnya.top/posts/dwn6rdfx/"><meta property="og:site_name" content="菲兹克斯喵"><meta property="og:title" content="物理与深度学习"><meta property="og:description" content="——解析本年度 Nobel Prize for Physics & Chemistry. 这是物理系办的一个讲座，主要围绕今年的 Nobel 物理学奖颁发给深度学习的两位专家这个话题展开. 我在讲座上记录了一些要点，觉得很有启发，所以放在这里作为一个存档. 介绍 人工智能（Artificial Intelligence）⊇ 机器学习（Machine L..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-02-11T14:39:06.000Z"><meta property="article:tag" content="Physics"><meta property="article:tag" content="interdisciplinarity"><meta property="article:tag" content="lecture"><meta property="article:modified_time" content="2025-02-11T14:39:06.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"物理与深度学习","image":[""],"dateModified":"2025-02-11T14:39:06.000Z","author":[]}</script><link rel="icon" type="image/jpg" href="images/Physics_nya.jpg"><link rel="stylesheet" type="text/css" href="https://chinese-fonts-cdn.deno.dev/packages/lxgwwenkai/dist/LXGWWenKai-Regular/result.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script><script src="https://umami.physnya.top/script.js" data-website-id="c412eaae-10f9-4820-99bf-a6410154a744"></script><link rel="alternate" type="application/atom+xml" href="https://physnya.top/atom.xml" title="菲兹克斯喵 Atom Feed"><title>物理与深度学习 | 菲兹克斯喵</title><meta name="description" content="——解析本年度 Nobel Prize for Physics & Chemistry. 这是物理系办的一个讲座，主要围绕今年的 Nobel 物理学奖颁发给深度学习的两位专家这个话题展开. 我在讲座上记录了一些要点，觉得很有启发，所以放在这里作为一个存档. 介绍 人工智能（Artificial Intelligence）⊇ 机器学习（Machine L..."><link rel="preload" href="/assets/style-BXYfx_-j.css" as="style"><link rel="stylesheet" href="/assets/style-BXYfx_-j.css"><link rel="modulepreload" href="/assets/app-DhJU2lep.js"><link rel="modulepreload" href="/assets/index.html-D488xEpl.js"></head><body><div id="app"><!--[--><!--[--><div class="theme-plume vp-layout" vp-container data-v-2ffd00ee><!--[--><!--[--><!--]--><!--[--><span tabindex="-1" data-v-632ca87f></span><a href="#VPContent" class="vp-skip-link visually-hidden" data-v-632ca87f> Skip to content </a><!--]--><!----><header class="vp-nav" data-v-2ffd00ee data-v-9f58167c><div class="vp-navbar" vp-navbar data-v-9f58167c data-v-d4c3947b><div class="wrapper" data-v-d4c3947b><div class="container" data-v-d4c3947b><div class="title" data-v-d4c3947b><div class="vp-navbar-title" data-v-d4c3947b data-v-77d2b52f><a class="vp-link no-icon link title" href="/" data-v-77d2b52f data-v-ab78d1cc><!--[--><!--[--><!--]--><!--[--><!--[--><!--[--><img class="vp-image dark logo" src="/images/Physics_nya.jpg" alt data-v-7a34c2b2><!--]--><!--[--><img class="vp-image light logo" src="/images/Physics_nya.jpg" alt data-v-7a34c2b2><!--]--><!--]--><!--]--><span data-v-77d2b52f>菲兹克斯喵</span><!--[--><!--]--><!--]--><!----></a></div></div><div class="content" data-v-d4c3947b><div class="content-body" data-v-d4c3947b><!--[--><!--]--><div class="vp-navbar-search search" data-v-d4c3947b><div class="search-wrapper" data-v-72f48e7b><!----><div id="local-search" data-v-72f48e7b><button type="button" class="mini-search mini-search-button" aria-label="搜索文档" data-v-72f48e7b><span class="mini-search-button-container"><span class="mini-search-search-icon vpi-mini-search" aria-label="search icon"></span><span class="mini-search-button-placeholder">搜索文档</span></span><span class="mini-search-button-keys"><kbd class="mini-search-button-key"></kbd><kbd class="mini-search-button-key">K</kbd></span></button></div></div></div><nav aria-labelledby="main-nav-aria-label" class="vp-navbar-menu menu" data-v-d4c3947b data-v-63c6c8d3><span id="main-nav-aria-label" class="visually-hidden" data-v-63c6c8d3>Main Navigation</span><!--[--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/" tabindex="0" data-v-63c6c8d3 data-v-2ba3f855 data-v-ab78d1cc><!--[--><!----><span data-v-2ba3f855>首页</span><!--]--><!----></a><!--]--><!--[--><a class="vp-link no-icon link navbar-menu-link" href="/blog/" tabindex="0" data-v-63c6c8d3 data-v-2ba3f855 data-v-ab78d1cc><!--[--><!----><span data-v-2ba3f855>博客</span><!--]--><!----></a><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-63c6c8d3 data-v-63f055cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-63f055cb><span class="text" data-v-63f055cb><!----><!----><span data-v-63f055cb>笔记</span><span class="vpi-chevron-down text-icon" data-v-63f055cb></span></span></button><div class="menu" data-v-63f055cb><div class="vp-menu" data-v-63f055cb data-v-f8364627><div class="items" data-v-f8364627><!--[--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/Feynman-III/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> Feynman III 札记<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/integral/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 高等微积分<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/cosmos/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 星系与宇宙<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/writing/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 写作与沟通<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-63c6c8d3 data-v-63f055cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-63f055cb><span class="text" data-v-63f055cb><!----><!----><span data-v-63f055cb>关于</span><span class="vpi-chevron-down text-icon" data-v-63f055cb></span></span></button><div class="menu" data-v-63f055cb><div class="vp-menu" data-v-63f055cb data-v-f8364627><div class="items" data-v-f8364627><!--[--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/about/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 关于我<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/timeline/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 时间线<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="vp-flyout vp-navbar-menu-group" data-v-63c6c8d3 data-v-63f055cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-63f055cb><span class="text" data-v-63f055cb><!----><!----><span data-v-63f055cb>友链</span><span class="vpi-chevron-down text-icon" data-v-63f055cb></span></span></button><div class="menu" data-v-63f055cb><div class="vp-menu" data-v-63f055cb data-v-f8364627><div class="items" data-v-f8364627><!--[--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/friends/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 友情链接<!--]--><!----></a></div><!--]--><!--[--><div class="vp-menu-link" data-v-f8364627 data-v-b6ab0577><a class="vp-link no-icon link" href="/links/" data-v-b6ab0577 data-v-ab78d1cc><!--[--><!----> 友链申请<!--]--><!----></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="vp-navbar-appearance appearance" data-v-d4c3947b data-v-36a184b9><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-36a184b9 data-v-ee1aa5e6 data-v-31fe4d80><span class="check" data-v-31fe4d80><span class="icon" data-v-31fe4d80><!--[--><span class="vpi-sun sun" data-v-ee1aa5e6></span><span class="vpi-moon moon" data-v-ee1aa5e6></span><!--]--></span></span></button></div><!----><div class="vp-flyout vp-navbar-extra extra" data-v-d4c3947b data-v-449e623f data-v-63f055cb><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-63f055cb><span class="vpi-more-horizontal icon" data-v-63f055cb></span></button><div class="menu" data-v-63f055cb><div class="vp-menu" data-v-63f055cb data-v-f8364627><!----><!--[--><!--[--><!----><div class="group" data-v-449e623f><div class="item appearance" data-v-449e623f><p class="label" data-v-449e623f>外观</p><div class="appearance-action" data-v-449e623f><button class="vp-switch vp-switch-appearance" type="button" role="switch" title aria-checked="false" data-v-449e623f data-v-ee1aa5e6 data-v-31fe4d80><span class="check" data-v-31fe4d80><span class="icon" data-v-31fe4d80><!--[--><span class="vpi-sun sun" data-v-ee1aa5e6></span><span class="vpi-moon moon" data-v-ee1aa5e6></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="vp-navbar-hamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="nav-screen" data-v-d4c3947b data-v-5e376614><span class="container" data-v-5e376614><span class="top" data-v-5e376614></span><span class="middle" data-v-5e376614></span><span class="bottom" data-v-5e376614></span></span></button></div></div></div></div><div class="divider" data-v-d4c3947b><div class="divider-line" data-v-d4c3947b></div></div></div><!----></header><div class="vp-local-nav fixed reached-top is-blog" data-v-2ffd00ee data-v-9c3549c4><button class="hidden menu" disabled aria-expanded="false" aria-controls="SidebarNav" data-v-9c3549c4><span class="vpi-align-left menu-icon" data-v-9c3549c4></span><span class="menu-text" data-v-9c3549c4>Menu</span></button><div class="vp-local-nav-outline-dropdown" style="--vp-vh:0px;" data-v-9c3549c4 data-v-a5380259><button data-v-a5380259>返回顶部</button><!----></div></div><!----><!--[--><div id="VPContent" vp-content class="vp-content" data-v-2ffd00ee data-v-6cfddd8b><div class="vp-doc-container is-blog" data-v-6cfddd8b data-v-c4524c5a><!--[--><!--]--><div class="container" data-v-c4524c5a><!----><div class="content" data-v-c4524c5a><div class="content-container" data-v-c4524c5a><!--[--><!--]--><main class="main" data-v-c4524c5a><nav class="vp-breadcrumb" data-v-c4524c5a data-v-012259c6><ol vocab="https://schema.org/" typeof="BreadcrumbList" data-v-012259c6><!--[--><li property="itemListElement" typeof="ListItem" data-v-012259c6><a class="vp-link no-icon link breadcrumb" href="/" property="item" typeof="WebPage" data-v-012259c6 data-v-ab78d1cc><!--[-->首页<!--]--><!----></a><span class="vpi-chevron-right" data-v-012259c6></span><meta property="name" content="首页" data-v-012259c6><meta property="position" content="1" data-v-012259c6></li><li property="itemListElement" typeof="ListItem" data-v-012259c6><a class="vp-link no-icon link breadcrumb" href="/blog/" property="item" typeof="WebPage" data-v-012259c6 data-v-ab78d1cc><!--[-->博客<!--]--><!----></a><span class="vpi-chevron-right" data-v-012259c6></span><meta property="name" content="博客" data-v-012259c6><meta property="position" content="2" data-v-012259c6></li><li property="itemListElement" typeof="ListItem" data-v-012259c6><a class="vp-link no-icon link breadcrumb" href="/blog/categories/?id=eed5ef" property="item" typeof="WebPage" data-v-012259c6 data-v-ab78d1cc><!--[-->lectures<!--]--><!----></a><span class="vpi-chevron-right" data-v-012259c6></span><meta property="name" content="lectures" data-v-012259c6><meta property="position" content="3" data-v-012259c6></li><li property="itemListElement" typeof="ListItem" data-v-012259c6><a class="vp-link no-icon link breadcrumb current" href="/posts/dwn6rdfx/" property="item" typeof="WebPage" data-v-012259c6 data-v-ab78d1cc><!--[-->物理与深度学习<!--]--><!----></a><!----><meta property="name" content="物理与深度学习" data-v-012259c6><meta property="position" content="4" data-v-012259c6></li><!--]--></ol></nav><!--[--><h1 class="vp-doc-title page-title" data-v-d197e3f4>物理与深度学习 <!----></h1><div class="vp-doc-meta" data-v-d197e3f4><p class="reading-time" data-v-d197e3f4><span class="vpi-books icon" data-v-d197e3f4></span><span data-v-d197e3f4>约 1747 字</span><span data-v-d197e3f4>大约 6 分钟</span></p><p data-v-d197e3f4><span class="vpi-tag icon" data-v-d197e3f4></span><!--[--><a class="vp-link no-icon link tag vp-tag-cgj5" href="/blog/tags/?tag=Physics" data-v-d197e3f4 data-v-ab78d1cc><!--[-->Physics<!--]--><!----></a><a class="vp-link no-icon link tag vp-tag-udk8" href="/blog/tags/?tag=interdisciplinarity" data-v-d197e3f4 data-v-ab78d1cc><!--[-->interdisciplinarity<!--]--><!----></a><a class="vp-link no-icon link tag vp-tag-lbsz" href="/blog/tags/?tag=lecture" data-v-d197e3f4 data-v-ab78d1cc><!--[-->lecture<!--]--><!----></a><!--]--></p><p class="create-time" data-v-d197e3f4><span class="vpi-clock icon" data-v-d197e3f4></span><span data-v-d197e3f4>2024-10-21</span></p></div><!--]--><div class="_posts_dwn6rdfx_ external-link-icon-enabled vp-doc plume-content" vp-content data-v-c4524c5a><div data-v-c4524c5a><p>——解析本年度 Nobel Prize for Physics &amp; Chemistry.</p><p>这是物理系办的一个讲座，主要围绕今年的 Nobel 物理学奖颁发给深度学习的两位专家这个话题展开. 我在讲座上记录了一些要点，觉得很有启发，所以放在这里作为一个存档.</p><h2 id="介绍" tabindex="-1"><a class="header-anchor" href="#介绍"><span>介绍</span></a></h2><p>人工智能（Artificial Intelligence）<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊇</mo></mrow><annotation encoding="application/x-tex">\supseteq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mrel">⊇</span></span></span></span> 机器学习（Machine Learning）<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊇</mo></mrow><annotation encoding="application/x-tex">\supseteq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mrel">⊇</span></span></span></span> 深度学习（Deep Learning），这是一个包含的关系. 深度学习是这个领域的前沿，用模拟人类神经网络的方式实现人工智能.</p><p>最早在1940年代，提出数学模型；1958年 Rosenblatt 感知器提出，是有隐藏层的前馈网络；日本科学家也在早期做出了很多奠基性工作.</p><p>1970年代，这个领域进入一个寒冬，因为难以处理数量巨大的神经元. 解决这个问题的正是 John Hopfield ，今年的 Nobel Prize for Physics 得主. 他1933年出生，1969得到巴克利奖（美国的一个凝聚态物理的奖项），之后想转到生物物理，但是后来发展出人工神经网络.</p><p>学过凝聚态物理的同学会知道，很多集体效应不是单个粒子的简单相加，而是呈现出非常特殊的统计性质. Hopfield 将这些思想应用到生物物理的领域中，他研究 DNA 的复制的试错，之后转向对联想记忆问题的研究.</p><blockquote><p>联想记忆：从不完整或者有偏差的输入，还原记忆内容；这是区别于传统的计算机存储的.</p></blockquote><p>Hopfield 考虑构建一个数学上的简单模型：Hopfield 网络，类似于 Ising Model ，神经元状态表征为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">s_i=0,1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span></span></span></span>，链接权重为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>w</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}=w_{ji}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，引入能量函数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mo>∑</mo><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>j</mi></mrow></msub><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>s</mi><mi>i</mi></msub><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">E=-\frac{1}{2}\sum_{i\neq j}w_{ij}s_is_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.4358em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>（这和 Ising Model 简直如出一辙！）</p><p>对这个网络做两件事情：</p><ol><li>训练：优化权重<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，用能量极小值的点<u>记录“记忆”</u>. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>→</mo></mrow><annotation encoding="application/x-tex">\to</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">→</span></span></span></span> 赫布定律（1949）</li><li>预测：固定<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，从输入的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>出发，优化 Hopfield 能量，<u>寻找相似的记忆</u>. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>→</mo></mrow><annotation encoding="application/x-tex">\to</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">→</span></span></span></span> 能量极小值对应“吸引子”，吸引子状态编码信息.</li></ol><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⟹</mo></mrow><annotation encoding="application/x-tex">\Longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.549em;vertical-align:-0.024em;"></span><span class="mrel">⟹</span></span></span></span> 借助能量函数存储记忆，通过优化能量函数还原记忆.</p><p>这种方式被应用在早期的一些算法问题上，比如“行商问题”. 经过长期发展，现在的“现代 Hopfield 网络”已经发展到新的样式，技术内核已经更新，但是设计理念没有太大变化.</p><p>接下来， Hinton 等人对 Boltzmann 机的研究将这些知识向前更进一步：这里关注能量函数的<u>概率分布</u>，用 Monte Carlo 方法计算结果. Boltzmann 机除了权重<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>以外还引入偏置<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，将能量极小值的记忆存储改为马尔科夫链蒙特卡洛算法（MCMC）产生的概率分布存储记忆，依靠新的方法进行训练.</p><p>Hinton 发展受限 Boltzmann 机，同层神经元之间无连接，使得理论得到大幅深入. 2017年，这种方法被用来求解量子多体问题.</p><p>Hinton 被称为“AI教父”，坚持挺过了 AI 研究的两度寒冬，不仅自己做出很多贡献，同时还培养了一批知名的学生，其中甚至有 OpenAI 的主要技术贡献者. 他们发现，当神经网络的 Scale 一旦变大，很多之前无法解决的问题都能迎刃而解.</p><p>之后的 AI 发展从两个角度出发：架构更先进、应用更广泛，前者的著名例子是卷积网络（CNN）的图像处理，而后者最著名的则是 ChatGPT.</p><p>Nobel 委员会在介绍此次颁奖的成果时，提到这项成果对于天体物理（黑洞计算）和 Alpha-Fold 等各种领域都实现了广泛的应用.</p><h2 id="和我们" tabindex="-1"><a class="header-anchor" href="#和我们"><span>和我们？</span></a></h2><p>徐老师谈谈 AI 对他自己专业的帮助：从基于经验到基于数据. 人工智能非常适合处理这样的问题：高维的参数空间、明确的优化目标、丰富的训练数据或高效的数据产生器，当满足这些条件时，AI 就变得非常强大，Alpha-Fold 就是一个绝佳的例子. 传统的科学计算在数值模拟耗时非常大，而有深度学习驱动的科学计算可以实现高效而智能的科学计算.</p><p>徐老师做的是第一性原理计算，即“基于量子力学原理，计算现实模型”. 这几年发展出高效的深度学习新一代第一性原理计算方法，将重要的物理先验融入神经网络，“压缩” DFT 底层算法，（局域性原理：小体系演化至大体系，速度快；协变性原理：进一步增强泛化能力，举一反三，可扩展性强）. 这是一个全新的材料研究方式：MIND（Material INtelligence Database）.</p><p>推荐一些开源的学习资料：<a href="https://github.com/mzjb/">mzjb</a>（是徐老师的学生）有很多 repo ，如徐老师和学生共同做的 DeepH .</p><h2 id="提问" tabindex="-1"><a class="header-anchor" href="#提问"><span>提问</span></a></h2><ul><li>神经网络发现物理规律的可解释性？</li></ul><p>让神经网络本身符合物理的特性，比如做反对称波函数的时候，整个神经网络本身就是反对称的；但是这还是一个非常重要而且专业的问题，也是学界关注的重点.</p><ul><li>其它学科的学生如何入门？</li></ul><p>学过四大力学，学 AI 就没有压力！之后， AI 可能会像英语一样成为一个普适的工具，反而更需要交叉学科的人才涌入. 未来会有很多可能性.</p><ul><li>AI for Physics &amp; Physics for AI？</li></ul><p>现在的 AI 像炼丹或者玄学，我们之后的工作或许是理解如何设计模型，才能让 AI 的发展更加健康；但是目前人们的目光主要聚焦在如何用好 AI 的方面.</p><ul><li>AI 的研究需要大量数据，如何收集或者产生？</li></ul><p>AI for Science 的应用中，有时需要数据产生器，或者通过经验优化模型，因为我们科学实验的数据是非常难以产生的.</p><ul><li>能否用 AI 设计 AI 算法？</li></ul><p>如果某一个 AI 专门被训练做这件事情，比如一个通用人工智能，很有可能实现.</p><h2 id="主持人的一些小分享" tabindex="-1"><a class="header-anchor" href="#主持人的一些小分享"><span>主持人的一些小分享</span></a></h2><p>其实 Hopfield 在 Ph.D 时期发的论文已经对凝聚态物理做出了很大的贡献，甚至有很多凝聚态的开创性工作，是一个非常纯正的 Theorist.</p></div><!----><!----><div class="vp-doc-copyright" data-v-c4524c5a><h2 id="doc-copyright" tabindex="-1" class="vp-doc-header" data-v-186454ca><a href="#doc-copyright" class="header-anchor" data-v-186454ca><span data-v-186454ca><!--[-->版权所有<!--]--></span></a></h2><div class="hint-container tip copyright-container" data-v-280da885><p data-v-280da885><span data-v-280da885>版权归属：</span><a class="vp-link no-icon link" href="https://github.com/physnya" target="_blank" rel="noreferrer" data-v-280da885 data-v-ab78d1cc><!--[-->physnya<!--]--><!----></a></p><p data-v-280da885><span data-v-280da885>本文链接：</span><a class="vp-link no-icon link" href="/posts/dwn6rdfx/" data-allow-mismatch data-v-280da885 data-v-ab78d1cc><!--[-->/posts/dwn6rdfx/<!--]--><!----></a></p><p data-v-280da885><span data-v-280da885>许可证：</span><a class="vp-link no-icon link" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noreferrer" data-v-280da885 data-v-ab78d1cc><!--[-->署名-非商业性-相同方式共享 4.0 国际 (CC-BY-NC-SA-4.0)<!--]--><!----></a><!--[--><span class="vpi-license-cc" data-v-280da885></span><span class="vpi-license-by" data-v-280da885></span><span class="vpi-license-nc" data-v-280da885></span><span class="vpi-license-sa" data-v-280da885></span><!--]--></p></div></div></div></main><footer class="vp-doc-footer" data-v-c4524c5a data-v-ef36450b><!--[--><!--]--><!----><div class="contributors" aria-label="Contributors" data-v-ef36450b><span class="contributors-label" data-v-ef36450b>贡献者: </span><span class="contributors-info" data-v-ef36450b><!--[--><!--[--><span class="contributor" data-v-ef36450b>physnya</span><!----><!--]--><!--]--></span></div><nav class="prev-next" data-v-ef36450b><div class="pager" data-v-ef36450b><a class="vp-link no-icon link pager-link prev" href="/posts/u9uwmglr/" data-v-ef36450b data-v-ab78d1cc><!--[--><span class="desc" data-v-ef36450b>上一页</span><span class="title" data-v-ef36450b>流水账 Week 7</span><!--]--><!----></a></div><div class="pager" data-v-ef36450b><a class="vp-link no-icon link pager-link next" href="/posts/mjf6caoa/" data-v-ef36450b data-v-ab78d1cc><!--[--><span class="desc" data-v-ef36450b>下一页</span><span class="title" data-v-ef36450b>流水账 Week 6</span><!--]--><!----></a></div></nav></footer><div id="comment" class="twikoo-wrapper vp-comment" vp-comment darkmode="false" style="display:block;" data-v-c4524c5a><div style="display: flex;
align-items: center;
justify-content: center;
height: 96px"><span style="--loading-icon: url(&quot;data:image/svg+xml;utf8,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; preserveAspectRatio=&#39;xMidYMid&#39; viewBox=&#39;25 25 50 50&#39;%3E%3CanimateTransform attributeName=&#39;transform&#39; type=&#39;rotate&#39; dur=&#39;2s&#39; keyTimes=&#39;0;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;360&#39;%3E%3C/animateTransform%3E%3Ccircle cx=&#39;50&#39; cy=&#39;50&#39; r=&#39;20&#39; fill=&#39;none&#39; stroke=&#39;currentColor&#39; stroke-width=&#39;4&#39; stroke-linecap=&#39;round&#39;%3E%3Canimate attributeName=&#39;stroke-dasharray&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;1,200;90,200;1,200&#39;%3E%3C/animate%3E%3Canimate attributeName=&#39;stroke-dashoffset&#39; dur=&#39;1.5s&#39; keyTimes=&#39;0;0.5;1&#39; repeatCount=&#39;indefinite&#39; values=&#39;0;-35px;-125px&#39;%3E%3C/animate%3E%3C/circle%3E%3C/svg%3E&quot;);
--icon-size: 48px;
display: inline-block;
width: var(--icon-size);
height: var(--icon-size);
background-color: currentcolor;
-webkit-mask-image: var(--loading-icon);
mask-image: var(--loading-icon);
"></span></div><div id="twikoo-comment"></div></div><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!--]--><button style="display:none;" type="button" class="vp-back-to-top" aria-label="back to top" data-v-2ffd00ee data-v-16cb9508><span class="percent" data-allow-mismatch data-v-16cb9508>0%</span><span class="show icon vpi-back-to-top" data-v-16cb9508></span><svg aria-hidden="true" data-v-16cb9508><circle cx="50%" cy="50%" data-allow-mismatch style="stroke-dasharray:calc(0% - 12.566370614359172px) calc(314.1592653589793% - 12.566370614359172px);" data-v-16cb9508></circle></svg></button><footer class="vp-footer" vp-footer data-v-2ffd00ee data-v-99fef671><!--[--><div class="container" data-v-99fef671><p class="message" data-v-99fef671>Powered by <a target="_blank" href="https://v2.vuepress.vuejs.org/">VuePress</a> & <a target="_blank" href="https://theme-plume.vuejs.press">vuepress-theme-plume</a></p><p class="copyright" data-v-99fef671>Copyright © 2024 - present by physnya</p></div><!--]--></footer><!--[--><!--]--><!--]--></div><!----><!--]--><!--[--><!--]--><!--]--></div><script type="module" src="/assets/app-DhJU2lep.js" defer></script></body></html>